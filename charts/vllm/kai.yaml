# # helm upgrade -i kai-scheduler oci://ghcr.io/nvidia/kai-scheduler/kai-scheduler -n kai-scheduler --create-namespace --version v0.12.12

# Pod Group to ensure gang scheduling
apiVersion: scheduling.sigs.k8s.io/v1alpha1
kind: PodGroup
metadata:
  name: {{ .Release.Name }}-podgroup
spec:
  minMember: {{ .Values.workers }}
  queueName: {{ .Values.system.queue | default "default" }}
---
# Headless service to allow service discovery
apiVersion: v1
kind: Service
metadata:
  name: {{ .Release.Name }}-headless
  labels:
    kai.scheduler/queue: {{ .Values.system.queue | default "default" }}
spec:
  clusterIP: None # Defines this as a Headless Service
  selector:
    # This must match the labels on your Leader Pod
    kalavai.job.name: {{ .Values.system.jobId }}
    role: leader
  ports:
  - name: ray-port
    port: 6379
    targetPort: 6379
  - name: ray-dashboard
    port: 8265
    targetPort: 8265
---
# --- LEADER JOB ---
apiVersion: batch/v1
kind: Job
metadata:
  name: {{ .Release.Name }}-leader
  labels:
    # KAI uses labels for queue and project association
    kai.scheduler/queue: {{ .Values.system.queue | default "default" }}
    kalavai.job.name: {{ .Values.system.jobId }}
    role: leader
spec:
  # The Pod-Grouper will automatically set minMember based on this
  parallelism: 1 
  completions: 1
  backoffLimit: 100 # Equivalent to maxRetry
  template:
    metadata:
      labels:
        # Essential: KAI tracks workloads via this label
        kai.scheduler/queue: {{ .Values.system.queue | default "default" }}
        kalavai.job.name: {{ .Values.system.jobId }}
        role: leader
      annotations:
        # If using fractional GPUs on NVIDIA:
        # gpu-fraction: "0.5" 
    spec:
      schedulerName: kai-scheduler
      priorityClassName: {{ .Values.system.jobPriority }}
      terminationGracePeriodSeconds: 60
      {{ if eq .Values.gpuBackend "cuda" }}
      runtimeClassName: nvidia
      {{ end }}
      {{- if .Values.system.nodeSelectors }}
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            {{- if eq .Values.system.nodeSelectorsOps "OR" }}
              {{- range $k, $v := .Values.system.nodeSelectors }}
              - matchExpressions:
                - key: {{ $k }}
                  operator: In
                  values: {{ $v | toJson }}
              {{- end }}
            {{- else }}
              - matchExpressions:
              {{- range $k, $v := .Values.system.nodeSelectors }}
                - key: {{ $k }}
                  operator: In
                  values: {{ $v | toJson }}
              {{- end }}
            {{- end }}
      {{- end }}

      containers:
      - name: vllm-leader
        image: ghcr.io/kalavai-net/vllm-{{ .Values.gpuBackend }}:{{ .Values.vllmVersion }}
        command:
        - sh
        - -c
        - |
          {{ if eq .Values.gpuBackend "cuda" }}
          nvidia-smi;
          {{ else }}
          rocm-smi;
          {{ end }}

          echo "Starting as Leader..."
          /home/ray/workspace/run_model.sh \
            --model_path="/home/ray/cache/{{ .Values.modelId }}" \
            --model_id={{ .Values.modelId}} \
            --model_name={{ .Values.modelNameOverride }} \
            --extra='{{ .Values.extra }}' \
            --template_url='{{ .Values.templateUrl }}' \
            --tensor_parallel_size={{ .Values.gpus }} \
            --pipeline_parallel_size={{ .Values.workers }} \
            --tool_call_parser={{ .Values.toolCallParser }} \
            --lora_modules="{{ .Values.loraModules }}"; 
        resources:
          limits:
            cpu: {{ .Values.cpus }}
            memory: {{ .Values.memory }}Gi
            {{- if eq .Values.gpuBackend "cuda" }}
            nvidia.com/gpu: {{ .Values.gpus }}
            {{- else }}
            amd.com/gpu: {{ .Values.gpus }}
            {{- end }}
          requests:
            cpu: {{ .Values.cpus }}
            memory: {{ .Values.memory }}Gi
            {{- if eq .Values.gpuBackend "cuda" }}
            nvidia.com/gpu: {{ .Values.gpus }}
            {{- else }}
            amd.com/gpu: {{ .Values.gpus }}
            {{- end }}
        volumeMounts:
          - mountPath: /dev/shm
            name: dshm
          - name: cache
            mountPath: /home/ray/cache
      volumes:
      - name: cache
        emptyDir: {}
      - name: dshm
        emptyDir:
          medium: Memory
          sizeLimit: {{ div .Values.memory 2 }}Gi
      restartPolicy: OnFailure
---
# --- WORKER JOB ---
{{- if gt (int .Values.workers) 1 }}
apiVersion: batch/v1
kind: Job
metadata:
  name: {{ .Release.Name }}-worker
  labels:
    # KAI uses labels for queue and project association
    kai.scheduler/queue: {{ .Values.system.queue | default "default" }}
    kalavai.job.name: {{ .Values.system.jobId }}
    role: worker
spec:
  # The Pod-Grouper will automatically set minMember based on this
  parallelism: {{ sub .Values.workers 1 }}
  completions: {{ sub .Values.workers 1 }}
  backoffLimit: 100 # Equivalent to maxRetry
  template:
    metadata:
      labels:
        # Essential: KAI tracks workloads via this label
        kai.scheduler/queue: {{ .Values.system.queue | default "default" }}
        kalavai.job.name: {{ .Values.system.jobId }}
        role: worker
      annotations:
        # If using fractional GPUs on NVIDIA:
        # gpu-fraction: "0.5" 
    spec:
      schedulerName: kai-scheduler
      priorityClassName: {{ .Values.system.jobPriority }}
      terminationGracePeriodSeconds: 60
      {{ if eq .Values.gpuBackend "cuda" }}
      runtimeClassName: nvidia
      {{ end }}
      {{- if .Values.system.nodeSelectors }}
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            {{- if eq .Values.system.nodeSelectorsOps "OR" }}
              {{- range $k, $v := .Values.system.nodeSelectors }}
              - matchExpressions:
                - key: {{ $k }}
                  operator: In
                  values: {{ $v | toJson }}
              {{- end }}
            {{- else }}
              - matchExpressions:
              {{- range $k, $v := .Values.system.nodeSelectors }}
                - key: {{ $k }}
                  operator: In
                  values: {{ $v | toJson }}
              {{- end }}
            {{- end }}
      {{- end }}

      containers:
      - name: vllm-worker
        image: ghcr.io/kalavai-net/vllm-{{ .Values.gpuBackend }}:{{ .Values.vllmVersion }}
        command:
        - sh
        - -c
        - |
          # SERVICE DISCOVERY CHANGE: 
          # Instead of /etc/volcano/server.host, use the service name you create
          LEADER_HOST="{{ .Release.Name }}-leader-svc"; 
          WORKER_ID=$JOB_COMPLETION_INDEX;
          
          {{ if eq .Values.gpuBackend "cuda" }}
          nvidia-smi;
          {{ else }}
          rocm-smi;
          {{ end }}

          echo "Starting as worker. Connecting to $LEADER_HOST......"
          RAY_BACKEND_LOG_LEVEL=error /home/ray/workspace/ray_init.sh worker --ray_address=$LEADER_HOST --ray_port=6379 --ray_object_store_memory={{ mul .Values.memory 500000000}} --ray_block=1
        resources:
          limits:
            cpu: {{ .Values.cpus }}
            memory: {{ .Values.memory }}Gi
            {{- if eq .Values.gpuBackend "cuda" }}
            nvidia.com/gpu: {{ .Values.gpus }}
            {{- else }}
            amd.com/gpu: {{ .Values.gpus }}
            {{- end }}
          requests:
            cpu: {{ .Values.cpus }}
            memory: {{ .Values.memory }}Gi
            {{- if eq .Values.gpuBackend "cuda" }}
            nvidia.com/gpu: {{ .Values.gpus }}
            {{- else }}
            amd.com/gpu: {{ .Values.gpus }}
            {{- end }}
        volumeMounts:
          - mountPath: /dev/shm
            name: dshm
          - name: cache
            mountPath: /home/ray/cache
      volumes:
      - name: cache
        emptyDir: {}
      - name: dshm
        emptyDir:
          medium: Memory
          sizeLimit: {{ div .Values.memory 2 }}Gi
      restartPolicy: OnFailure
{{- end }}